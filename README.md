# â˜ï¸ cf_ai_cloudflare_chat â€” Llama 3.3 Ã— Workflows Ã— Durable Objects Ã— Pages  

**Live Worker API:** [hello-worker.maitreyasanjay-vaghulade.workers.dev](https://hello-worker.maitreyasanjay-vaghulade.workers.dev)  
**Live Frontend (Pages):** [cloudflare-ai-chat-kmo.pages.dev/chat](https://cloudflare-ai-chat-kmo.pages.dev/chat)
**email**: maitreyasanjay.vaghulade@stonybrook.edu

---

## ğŸš€ Overview

This repository is an **original submission** for Cloudflareâ€™s **AI-Powered Application Assignment**.  
It demonstrates how to build a fully serverless AI app using **Cloudflare Workers AI**, **Workflows**, **Durable Objects**, and **Pages**.

| Component | Description |
|------------|--------------|
| **LLM** | Llama 3.3 70B Instruct FP8 Fast on **Workers AI** |
| **Workflow / Coordination** | Cloudflare **Workflows** (`ChatWorkflow`) |
| **Memory / State** | Cloudflare **Durable Objects** (`SessionDurableObject`) |
| **Frontend** | Minimal **Pages** chat UI |
| **Routing / CORS** | Handled inside Worker with full preflight support |

---

## ğŸ§  Features

- ğŸ”¹ Realtime chat with **Llama 3.3**
- ğŸ”¹ **Durable Object** memory (10-turn history per session)
- ğŸ”¹ **Workflows** for multi-step orchestration (LLM â†’ persist)
- ğŸ”¹ **Pages** UI for user input
- ğŸ”¹ Fully deployable via Wrangler 4 (no servers!)

---

## ğŸ§© Architecture

```text
[ Pages Chat UI (/chat) ]
        â”‚
        â–¼
  [ Worker /chat ]
        â”‚
        â”œâ”€â”€â†’ Workers AI  (LLM inference)
        â”‚
        â””â”€â”€â†’ Durable Object  (state persistence)
                    â”‚
                    â–¼
            Per-session memory (last 10 turns)

Optionally:
[ Worker /wf ] â†’ Workflows (ChatWorkflow â†’ LLM + save)

ğŸ§± Tech Stack

Cloudflare Workers
Workers AI (Llama 3.3)
Durable Objects
Workflows
Pages
TypeScript + Wrangler 4

âš™ï¸ Configuration â€” wrangler.toml
name = "hello-worker"
main = "src/worker.ts"
compatibility_date = "2025-11-01"

[ai]
binding = "AI"

[[durable_objects.bindings]]
name = "SessionDO"
class_name = "SessionDurableObject"

[[migrations]]
tag = "v1"
new_sqlite_classes = ["SessionDurableObject"]

[[workflows]]
name = "chat-workflow"
class_name = "ChatWorkflow"
binding = "MY_WORKFLOW"

ğŸ“ Folder Structure
cf_ai_cloudflare_chat/
â”œâ”€ wrangler.toml
â”œâ”€ tsconfig.json
â”œâ”€ src/
â”‚  â””â”€ worker.ts          # Worker + DO + Workflow
â””â”€ pages/
   â””â”€ chat.html          # Frontend UI

ğŸ’¬ API Endpoints
POST /chat
Performs a single LLM call + saves it.

Body
{ "sessionId": "demo", "message": "One short sentence about Cloudflare Workers" }

Response
{ "reply": "Cloudflare Workers let you run code globally at the edge." }

curl -X POST https://hello-worker.maitreyasanjay-vaghulade.workers.dev/chat \
  -H "content-type: application/json" \
  -d '{"sessionId":"demo","message":"Hello!"}'

ğŸ–¥ï¸ Front-End (pages/chat.html)

Hosted on Cloudflare Pages, connects to the Workerâ€™s /chat.

<script>
  const API = "https://hello-worker.maitreyasanjay-vaghulade.workers.dev/chat";
  const log = document.getElementById("log");
  const msg = document.getElementById("msg");
  const send = document.getElementById("send");
  const sessionId = "demo";

  send.onclick = sendMsg;
  msg.addEventListener("keydown", e => { if (e.key === "Enter") sendMsg(); });

  async function sendMsg() {
    const m = msg.value.trim();
    if (!m) return;
    append(`You: ${m}`); msg.value = "";
    try {
      const r = await fetch(API, {
        method: "POST",
        headers: {"content-type":"application/json"},
        body: JSON.stringify({ message: m, sessionId })
      });
      const j = await r.json();
      append(`AI: ${j.reply}`);
    } catch (err) {
      append(`âŒ ${err}`);
    }
  }
  function append(t){ log.textContent += "\n" + t; }
</script>

ğŸ§  Memory / State

Each sessionId â†’ one Durable Object instance storing:

{ "user": "<prompt>", "ai": "<reply>", "at": 1730490000000 }

Only the last 10 turns are kept.

ğŸ§ª Local Development
# dev mode
npx wrangler dev

# deploy worker
npx wrangler deploy

# deploy pages frontend
npx wrangler pages deploy ./pages --project-name cloudflare-ai-chat --branch=main

âœ… Rubric Mapping
Requirement	Implementation
LLM	Workers AI (Llama 3.3 70B Instruct FP8 Fast)
Workflow / Coordination	Cloudflare Workflows + Durable Objects
User Input via Chat / Voice	Chat UI on Pages
Memory or State	Durable Object persistence
Documentation	This README.md + live links
Originality	100% original implementation

ğŸ§¾ Running Instructions Summary

Clone the repo

git clone https://github.com/<your-username>/cf_ai_cloudflare_chat.git
cd cf_ai_cloudflare_chat/hello-worker


Install deps

npm i -D @cloudflare/workers-types


Develop or deploy

npx wrangler dev
npx wrangler deploy


Access

API: hello-worker.maitreyasanjay-vaghulade.workers.dev/chat

UI: cloudflare-ai-chat-kmo.pages.dev/chat

ğŸ§© Demo Flow

Open the Pages chat link
Type a message â†’ Worker / chat
Worker â†’ Workers AI â†’ Durable Object
Reply displayed instantly, session stored for context

ğŸ§® Tech Highlights

CORS handled natively (OPTIONS â†’ 204 + access-control headers)
Async Workflows for multi-step orchestration
DO migration using new_sqlite_classes for Free Plan compatibility
Fully edge-native (no external backend)

ğŸ“œ License

MIT Â© 2025 Maitreya Sanjay Vaghulade
Built exclusively for Cloudflare SWE Intern Assignment
